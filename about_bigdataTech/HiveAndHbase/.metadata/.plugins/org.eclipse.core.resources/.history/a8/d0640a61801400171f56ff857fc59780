import java.sql.Connection;
import java.sql.DriverManager;
import java.sql.ResultSet;
import java.sql.SQLException;
import java.sql.Statement;

//import org.apache.log4j.Logger;

public class HiveDemo {

	private static String sql = "";
	private static ResultSet res;

	// 用java操作之前先要打开hive服务 hive --service hiveserver2 &
	public static void main(String[] args) throws Exception {

		try {
			Connection con = MyConnection.getHiveInstance();
			Statement stmt = con.createStatement();
			
//			showTables(stmt);
//			describeTables(stmt, "mxn01");
		    loadData(stmt, "netinfoBandDelayJetter");
//		    selectData(stmt, "netinfoBandDelayJetter");

			// selectData2(stmt, "mxn01");
			// countData(stmt, "mxn01");
			//createTable(stmt, "netinfoBandDelayJetter");
			// loadData(stmt, "mxn01");
			showTables(stmt);
			//dropTable(stmt, "netinfo");
		} catch (ClassNotFoundException e) {
			// TODO Auto-generated catch block
			e.printStackTrace();
		}

	}

	// 显示表
	private static void showTables(Statement stmt) throws SQLException {
		sql = "show tables";
		System.out.println("Running:" + sql);
		res = stmt.executeQuery(sql);
		System.out.println("执行 show tables 运行结果:");
		while (res.next()) {
			System.out.println(res.getString(1));
		}
	}

	// 创建表
	private static void createTable(Statement stmt, String tableName) throws SQLException {
		sql = "create table " + tableName + " (id int, bandwidth string,delay string,jetter string,time string)  row format delimited fields terminated by '\t'";
		stmt.execute(sql);
		System.out.println("表创建成功");
	}

	// 删除表
	private static String dropTable(Statement stmt, String tableName) throws SQLException {
		sql = "drop table " + tableName;
		stmt.execute(sql);
		System.out.println("表删除成功");
		return tableName;
	}

	// 统计表中数据
	private static void countData(Statement stmt, String tableName) throws SQLException {
		// stmt.execute("set hive.optimize.ppd=false");
		sql = "select count(1) from " + tableName;
		System.out.println("Running:" + sql);
		res = stmt.executeQuery(sql);
		System.out.println("执行“regular hive query”运行结果:");
		while (res.next()) {
			System.out.println("count ------>" + res.getString(1));
		}
	}

	// 选择特定数据
	private static void selectData2(Statement stmt, String tableName) throws SQLException {
		// 这句话不能少
		stmt.execute("set hive.optimize.ppd=false");
		sql = "select * from " + tableName + " where key = 1";
		System.out.println("Running:" + sql);
		res = stmt.executeQuery(sql);
		System.out.println("执行 select * query 运行结果:");
		while (res.next()) {
			System.out.println(res.getInt(1) + "\t" + res.getString(2));
		}
	}

	// 选择数据
	private static void selectData(Statement stmt, String tableName) throws SQLException {
		sql = "select * from " + tableName;
		System.out.println("Running:" + sql);
		res = stmt.executeQuery(sql);
		System.out.println("执行 select * query 运行结果:");
		while (res.next()) {
			System.out.println(res.getInt(1) + "\t" + res.getString(2));
		}
	}

	// 载入数据
	private static void loadData(Statement stmt, String tableName) throws SQLException {
		// String filepath = "/home/ubuntu/11.txt";
		String filepath = "/input/netWorkInfo/17_03_22_02_43_24packetInfo_bandwidth.txt";
		// sql = "load data local inpath '" + filepath + "' into table " +   这是从本地上导入 多了local
		// tableName;// 从本地
		sql = "load data inpath '" + filepath + "' into table " + tableName;// 从
																			// hdfs上导入
		System.out.println("Running:" + sql);
		stmt.execute(sql);
		System.out.println("数据导入成功");
	}

	// 表描述
	private static void describeTables(Statement stmt, String tableName) throws SQLException {
		sql = "describe " + tableName;
		System.out.println("Running:" + sql);
		res = stmt.executeQuery(sql);
		System.out.println("执行 describe table 运行结果:");
		while (res.next()) {
			System.out.println(res.getString(1) + "\t" + res.getString(2));
		}
	}
}
